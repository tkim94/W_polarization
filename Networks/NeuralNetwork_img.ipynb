{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.models import Sequential,Model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import UpSampling2D\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Dropout, BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ReduceLROnPlateau,EarlyStopping\n",
    "from matplotlib import pyplot\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neutral Network Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "import pydot, graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------\n",
    "# Define Sampling Layer\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape=(batch,dim))#, mean=0., std=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_sigma) * epsilon\n",
    "\n",
    "batch_size = 128\n",
    "latent_dim = 3\n",
    "\n",
    "input_img = Input(shape = (1,20,20))\n",
    "\n",
    "layer_1 = Conv2D(10, kernel_size=4,padding=\"same\", activation = 'relu')(input_img)\n",
    "layer_2 = Conv2D(10, kernel_size=4,padding=\"same\", activation = 'relu')(layer_1)\n",
    "pooling = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(layer_2)\n",
    "layer_3 = Conv2D(5, kernel_size=2,padding=\"same\", activation = 'relu')(pooling)\n",
    "layer_4 = Conv2D(5, kernel_size=2,padding=\"same\", activation = 'relu')(layer_3)\n",
    "flatten = Flatten()(layer_4)\n",
    "\n",
    "dense_1 = Dense(units=100, activation='relu')(flatten)\n",
    "dense_2 = Dense(units=50, activation='relu')(dense_1)\n",
    "\n",
    "# Latent space\n",
    "z_mean = Dense(units=latent_dim)(dense_2)\n",
    "z_log_sigma = Dense(units=latent_dim)(dense_2)\n",
    "\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean,z_log_sigma])\n",
    "\n",
    "# Decoder\n",
    "dense_3 = Dense(units=50, activation='relu')(z)\n",
    "dense_4 = Dense(units=100, activation='relu')(dense_3)\n",
    "reshape = Reshape((1,10,10))(dense_4)\n",
    "layer_5 = Conv2D(5, kernel_size=2,padding=\"same\", activation = 'relu')(reshape)\n",
    "layer_6 = Conv2D(5, kernel_size=2,padding=\"same\", activation = 'relu')(layer_5)\n",
    "upsample = UpSampling2D((2,2))(layer_6)\n",
    "layer_7 = Conv2D(10, kernel_size=4,padding=\"same\", activation = 'relu')(upsample)\n",
    "\n",
    "decoded = Conv2D(1, kernel_size=4,padding=\"same\", activation = 'softmax')(layer_7)\n",
    "\n",
    "\n",
    "vae = Model(input_img, decoded)\n",
    "#vae.summary() # show summary of the network\n",
    "\n",
    "plot_model(vae, show_shapes=True, show_layer_names=True,to_file='VAE.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape = (1,20,20))\n",
    "\n",
    "layer_1 = Conv2D(10, kernel_size=4,padding=\"same\", activation = 'relu')(input_img)\n",
    "layer_2 = Conv2D(10, kernel_size=4,padding=\"same\", activation = 'relu')(layer_1)\n",
    "pooling = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(layer_2)\n",
    "layer_3 = Conv2D(5, kernel_size=2,padding=\"same\", activation = 'relu')(pooling)\n",
    "layer_4 = Conv2D(5, kernel_size=2,padding=\"same\", activation = 'relu')(layer_3)\n",
    "flatten = Flatten()(layer_4)\n",
    "\n",
    "dense_1 = Dense(units=100, activation='relu')(flatten)\n",
    "dense_2 = Dense(units=50, activation='relu')(dense_1)\n",
    "encoded = Dense(units=20)(dense_2)\n",
    "\n",
    "# Decoder\n",
    "dense_3 = Dense(units=50, activation='relu')(encoded)\n",
    "dense_4 = Dense(units=100, activation='relu')(dense_3)\n",
    "reshape = Reshape((1,10,10))(dense_4)\n",
    "layer_5 = Conv2D(5, kernel_size=2,padding=\"same\", activation = 'relu')(reshape)\n",
    "layer_6 = Conv2D(5, kernel_size=2,padding=\"same\", activation = 'relu')(layer_5)\n",
    "upsample = UpSampling2D((2,2))(layer_6)\n",
    "layer_7 = Conv2D(10, kernel_size=4,padding=\"same\", activation = 'relu')(upsample)\n",
    "\n",
    "decoded = Conv2D(1, kernel_size=4,padding=\"same\", activation = 'softmax')(layer_7)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "#autoencoder.summary()\n",
    "\n",
    "plot_model(autoencoder, show_shapes=True, show_layer_names=True,to_file='autoencoder.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative way to make sequential (not ideal)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(20, kernel_size=4,input_shape=(1, 20, 20), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "#model.add(Conv2D(40, kernel_size=4, padding=\"same\", activation = 'relu'))\n",
    "model.add(Conv2D(40, kernel_size=4, padding=\"same\", activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=300, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=50, activation='relu'))\n",
    "model.add(Dense(units=3, activation = 'softmax'))\n",
    "\n",
    "#model.summary()\n",
    "plot_model(model, show_shapes=True, show_layer_names=True,to_file='CNN_1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Channel 1\n",
    "input_img = Input(shape = (1,20,20))\n",
    "input_cnn = Conv2D(5, kernel_size=4,padding=\"same\", activation = 'relu')(input_img)\n",
    "\n",
    "# ResNet Unit 1 - 1\n",
    "d1p1_1 = Conv2D(10, kernel_size=4,padding=\"same\")(input_cnn)\n",
    "d1p1_1_norm = BatchNormalization()(d1p1_1)\n",
    "d1p1_activ = Activation('relu')(d1p1_1_norm)\n",
    "d1p1_2 = Conv2D(5, kernel_size=4,padding=\"same\")(d1p1_activ)\n",
    "d1p1_2_norm = BatchNormalization()(d1p1_2)\n",
    "\n",
    "# ResNet Unit 1 - 2\n",
    "d1p2_1 = Conv2D(5, kernel_size=4,padding=\"same\")(input_cnn)\n",
    "d1p2_1_norm = BatchNormalization()(d1p2_1)\n",
    "d1p2_activ = Activation('relu')(d1p2_1_norm)\n",
    "d1p2_2 = Conv2D(5, kernel_size=4,padding=\"same\")(d1p2_activ)\n",
    "d1p2_2_norm = BatchNormalization()(d1p2_2)\n",
    "\n",
    "# Add layers\n",
    "d1_sum = keras.layers.add([input_cnn, d1p1_2_norm, d1p2_2_norm])\n",
    "d1_sum_activ = Activation('relu')(d1_sum)\n",
    "\n",
    "\n",
    "# ResNet Unit 2 - 1\n",
    "d2p1_1 = Conv2D(10, kernel_size=4,padding=\"same\")(d1_sum_activ)\n",
    "d2p1_1_norm = BatchNormalization()(d2p1_1)\n",
    "d2p1_activ = Activation('relu')(d2p1_1_norm)\n",
    "d2p1_2 = Conv2D(5, kernel_size=4,padding=\"same\")(d2p1_activ)\n",
    "d2p1_2_norm = BatchNormalization()(d2p1_2)\n",
    "\n",
    "# ResNet Unit 2 - 2\n",
    "d2p2_1 = Conv2D(5, kernel_size=4,padding=\"same\")(d1_sum_activ)\n",
    "d2p2_1_norm = BatchNormalization()(d2p2_1)\n",
    "d2p2_activ = Activation('relu')(d2p2_1_norm)\n",
    "d2p2_2 = Conv2D(5, kernel_size=4,padding=\"same\")(d2p2_activ)\n",
    "d2p2_2_norm = BatchNormalization()(d2p2_2)\n",
    "\n",
    "# Add layers\n",
    "d2_sum = keras.layers.add([d1_sum_activ, d2p1_2_norm, d2p2_2_norm])\n",
    "d2_sum_activ = Activation('relu')(d2_sum)\n",
    "\n",
    "\n",
    "# ResNet Unit 3 - 1\n",
    "d3p1_1 = Conv2D(10, kernel_size=4,padding=\"same\")(d2_sum_activ)\n",
    "d3p1_1_norm = BatchNormalization()(d3p1_1)\n",
    "d3p1_activ = Activation('relu')(d3p1_1_norm)\n",
    "d3p1_2 = Conv2D(5, kernel_size=4,padding=\"same\")(d3p1_activ)\n",
    "d3p1_2_norm = BatchNormalization()(d3p1_2)\n",
    "\n",
    "# ResNet Unit 3 - 2\n",
    "d3p2_1 = Conv2D(5, kernel_size=4,padding=\"same\")(d2_sum_activ)\n",
    "d3p2_1_norm = BatchNormalization()(d3p2_1)\n",
    "d3p2_activ = Activation('relu')(d3p2_1_norm)\n",
    "d3p2_2 = Conv2D(5, kernel_size=4,padding=\"same\")(d3p2_activ)\n",
    "d3p2_2_norm = BatchNormalization()(d3p2_2)\n",
    "\n",
    "# Add layers\n",
    "d3_sum = keras.layers.add([d2_sum_activ, d3p1_2_norm, d3p2_2_norm])\n",
    "d3_sum_activ = Activation('relu')(d3_sum)\n",
    "\n",
    "\n",
    "# Down sampling \n",
    "d4down = Conv2D(10, kernel_size=4,strides=2,padding=\"same\")(d3_sum_activ)\n",
    "d4down_norm = BatchNormalization()(d4down)\n",
    "\n",
    "# ResNet Unit 4 - 1\n",
    "d4p1_1 = Conv2D(20, kernel_size=4,strides=2,padding=\"same\")(d3_sum_activ)\n",
    "d4p1_1_norm = BatchNormalization()(d4p1_1)\n",
    "d4p1_activ = Activation('relu')(d4p1_1_norm)\n",
    "d4p1_2 = Conv2D(10, kernel_size=4,padding=\"same\")(d4p1_activ)\n",
    "d4p1_2_norm = BatchNormalization()(d4p1_2)\n",
    "\n",
    "# ResNet Unit 4 - 2\n",
    "d4p2_1 = Conv2D(10, kernel_size=4,strides=2,padding=\"same\")(d3_sum_activ)\n",
    "d4p2_1_norm = BatchNormalization()(d4p2_1)\n",
    "d4p2_activ = Activation('relu')(d4p2_1_norm)\n",
    "d4p2_2 = Conv2D(10, kernel_size=4,padding=\"same\")(d4p2_activ)\n",
    "d4p2_2_norm = BatchNormalization()(d4p2_2)\n",
    "\n",
    "# Add layers\n",
    "d4_sum = keras.layers.add([d4down_norm, d4p1_2_norm, d4p2_2_norm])\n",
    "d4_sum_activ = Activation('relu')(d4_sum)\n",
    "\n",
    "flatten = Flatten()(d4_sum_activ)\n",
    "\n",
    "dense_1 = Dense(units=200, activation='relu')(flatten)\n",
    "dense_2 = Dense(units=100, activation='relu')(dense_1)\n",
    "classify = Dense(units=3, activation='softmax')(dense_2)\n",
    "\n",
    "\n",
    "ResNet = Model(input_img, classify)\n",
    "plot_model(ResNet, show_shapes=True, show_layer_names=True,to_file='resnet_model.png')\n",
    "#print ResNet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Better way to CNN\n",
    "input_img = Input(shape = (1,20,20))\n",
    "input_cnn = Conv2D(20, kernel_size=4,padding=\"same\", activation = 'relu')(input_img)\n",
    "maxpool1 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(input_cnn)\n",
    "dropout1 = Dropout(0.3)(maxpool1)\n",
    "conv1 = Conv2D(40, kernel_size=4, padding=\"same\", activation = 'relu')(dropout1)\n",
    "maxpool2 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(conv1)\n",
    "dropout2 = Dropout(0.3)(maxpool2)\n",
    "\n",
    "flat = Flatten()(dropout2)\n",
    "\n",
    "dense1 = Dense(units=300, activation='relu')(flat)\n",
    "dropout3 = Dropout(0.3)(dense1)\n",
    "dense2 = Dense(units=100, activation='relu')(dropout3)\n",
    "dense3 = Dense(units=100, activation='relu')(dense2)\n",
    "final = Dense(units=1, activation = 'sigmoid')(dense3)\n",
    "\n",
    "\n",
    "CNNmodel = Model(input_img, final)\n",
    "\n",
    "# plot_model not working due to some $PATH problem\n",
    "plot_model(CNNmodel, show_shapes=True, show_layer_names=True,to_file='CNN_model.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNNmodel.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy','binary_crossentropy'])\n",
    "\n",
    "# enable early stopping based on mean_squared_error\n",
    "earlystopping = EarlyStopping(monitor=\"binary_crossentropy\", patience=20, verbose=1, mode='auto')\n",
    "\n",
    "\n",
    "# Reduce learning rate(lr) when a metric has stopped improving\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.1,\n",
    "                             patience=10, min_lr = 0.0001) \n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=400, verbose=2, \n",
    "                      batch_size=32, callbacks=[reduce_lr,earlystopping], validation_data=(X_test, Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
